{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUrnIgkvtWeh",
        "outputId": "b5788d3f-edb1-4e84-a85f-3fd8a600bec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-hub (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-nlp 0.18.1 requires keras-hub==0.18.1, but you have keras-hub 0.20.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/keras-team/keras-hub.git -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
        "\n",
        "import keras_hub\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
      ],
      "metadata": {
        "id": "Vsu1XDiTwF6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = keras_hub.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length=128,\n",
        ")\n",
        "gpt2_lm = keras_hub.models.GPT2CausalLM.from_preset(\n",
        "    \"gpt2_base_en\", preprocessor=preprocessor\n",
        ")"
      ],
      "metadata": {
        "id": "W2l32RS0wJgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875c812f-202d-4e25-f328-acb6be5f59c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/config.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 484/484 [00:00<00:00, 757kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/tokenizer.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 448/448 [00:00<00:00, 748kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/assets/tokenizer/vocabulary.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 13.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/assets/tokenizer/merges.txt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 446k/446k [00:00<00:00, 8.24MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/model.weights.h5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 475M/475M [00:09<00:00, 53.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X9W9MB0GN7Y",
        "outputId": "0f697286-23da-43d5-b7d7-43ebf6da70c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "My trip to Yosemite was a great experience! I went to a great place, I was very impressed with the view and the weather, and I was really happy.\n",
            "\n",
            "I was very surprised to find a place to eat, a restaurant, and a great view of the park. I was also very excited about the weather and the view, and the weather was nice. I am very glad to have been there.\n",
            "\n",
            "The weather is good. The park is very well maintained and I have been able to enjoy the views from the top of the mountain. I will definitely be back.\n",
            "\n",
            "This was a great experience! I had the opportunity to take in the spectacular view of the park from the summit of Mt. Elsinore, the top and the summit of Mt. Hood, and to take pictures with my camera. It is very nice to be here. I will definitely return. Thank you, Mountain View!\n",
            "\n",
            "I am so glad to be back here and I\n",
            "TOTAL TIME ELAPSED: 50.68s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"That Italian restaurant is\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXRtVH-jGP_T",
        "outputId": "b39129f6-076e-4dd0-d855-6f11e45cb3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "That Italian restaurant is a good place to go for a quick meal and a drink, and I'm not even going to go back. I think it is a great place to get a drink and some wine and a beer. It's a great location to hang out and have a beer, a wine and a beer. It's a great restaurant with great seating and great food, and I'm going to come back.\n",
            "\n",
            "I've been to Italy before and I've never felt the need to go back. But this Italian place is amazing! The staff has a very good selection of food. I have never been here in a restaurant before. And the staff is always friendly and attentive. It's a great place to go and I'm sure they will do the same with me! I would definitely stay here again.\n",
            "\n",
            "I was going for a quick meal and drink at this Italian restaurant. I had a great time and the staff are friendly. They were great. I will definitely\n",
            "TOTAL TIME ELAPSED: 17.26s\n"
          ]
        }
      ]
    }
  ]
}